{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitmlfornlpconda8a01b745126c4bdcbb8300cda524a33d",
   "display_name": "Python 3.8.3 64-bit ('ml-for-nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train = fetch_20newsgroups(subset='train', categories=['alt.atheism', 'talk.religion.misc'])\n",
    "vectorizer = CountVectorizer(stop_words=\"english\", min_df=5)\n",
    "vectors = np.asarray(vectorizer.fit_transform(train.data).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassification(object):\n",
    "    def fit(self, X, y):\n",
    "        num_class = np.unique(y).shape[0]\n",
    "\n",
    "        self.prior = np.zeros((num_class))\n",
    "        for i in range(num_class):\n",
    "            self.prior[i] = (y == 1).sum() / y.shape[0]\n",
    "\n",
    "        # Assumming the features are in the representation of bag-of-words\n",
    "        x_by_c = np.array([X[y == c] for c in range(num_class)]) + 1.0\n",
    "        sum_words = np.array([arr.sum(0) for arr in x_by_c])\n",
    "        total_words = sum_words.sum()\n",
    "        self.likelihood = sum_words / total_words\n",
    "\n",
    "    def predict(self, X):\n",
    "        posterior = np.zeros((X.shape[0], self.prior.shape[0]))\n",
    "        for i, x in enumerate(X):\n",
    "            pos = x.astype(bool)\n",
    "            likelihood = self.likelihood[:, pos]\n",
    "            likelihood = likelihood.prod(1)\n",
    "            posterior[i] = self.prior * likelihood\n",
    "        proba = posterior / posterior.sum(1).reshape(-1, 1)\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = NaiveBayesClassification()\n",
    "c.fit(vectors, train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(111, 0.0)"
      ]
     },
     "metadata": {},
     "execution_count": 240
    }
   ],
   "source": [
    "vectors[3].astype(bool).sum(), np.exp(np.log(c.likelihood[:, vectors[3].astype(bool)]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.43990665, 0.43990665]),\n",
       " array([[0.00013282, 0.00014134, 0.00013529, ..., 0.00013199, 0.00013474,\n",
       "         0.00013282],\n",
       "        [0.00010477, 0.00010834, 0.00010532, ..., 0.00010587, 0.00010394,\n",
       "         0.00010669]]))"
      ]
     },
     "metadata": {},
     "execution_count": 241
    }
   ],
   "source": [
    "c.prior, c.likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[9.99996866e-01, 3.13446690e-06],\n",
       "       [9.99999961e-01, 3.85015766e-08],\n",
       "       [           nan,            nan],\n",
       "       ...,\n",
       "       [           nan,            nan],\n",
       "       [9.99998718e-01, 1.28170010e-06],\n",
       "       [           nan,            nan]])"
      ]
     },
     "metadata": {},
     "execution_count": 242
    }
   ],
   "source": [
    "c.predict(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = MultinomialNB().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.05382675, 0.94617325],\n",
       "       [0.10215483, 0.89784517],\n",
       "       [0.14578588, 0.85421412],\n",
       "       [0.96919027, 0.03080973],\n",
       "       [0.62098241, 0.37901759],\n",
       "       [0.80376766, 0.19623234],\n",
       "       [0.92474413, 0.07525587]])"
      ]
     },
     "metadata": {},
     "execution_count": 220
    }
   ],
   "source": [
    "bench.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}